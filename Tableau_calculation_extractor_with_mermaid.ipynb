{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3.1\n",
    "\n",
    "import pandas as pd\n",
    "import os, re, sys\n",
    "import string\n",
    "import webbrowser\n",
    "\n",
    "from tableaudocumentapi import Workbook\n",
    "from os.path import isfile, join\n",
    "\n",
    "import excelgenerator as exg\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Handling\n",
    "\n",
    "- this version of code will only work with twbx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_path = \"inputs\"\n",
    "output_path = \"outputs\"\n",
    "\n",
    "mypath = \"./{}\".format(input_path)   #./ points to \"this path\" as a relative path\n",
    "\n",
    "mypath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only gets files and not directories within the inputs folder -https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "input_files = [f for f in os.listdir(mypath) if isfile(join(mypath, f)) and f[-5:] == '.twbx'] \n",
    "#input_files.pop()\n",
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharFromStr(spstring):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     input: string\n",
    "#     output: new string, without any special char\n",
    "#     \"\"\"\n",
    "    \n",
    "    return ''.join(e for e in spstring if e.isalnum())\n",
    "\n",
    "def removeSpecialCharFromStr_leaveSpaces(spstring):\n",
    "  \n",
    "    return ''.join(e for e in spstring if (e.isalnum() or e ==' '))\n",
    "\n",
    "def remove_sp_char_then_turn_spaces_into_underscore(string_to_convert):\n",
    "    filtered_string = re.sub(r'[^a-zA-Z0-9\\s_]', '', string_to_convert).replace(' ', \"_\")\n",
    "    return filtered_string\n",
    "\n",
    "def remove_sp_char_leave_undescore_square_brackets(string_to_convert):\n",
    "    filtered_string = re.sub(r'[^a-zA-Z0-9\\s._\\[\\]]', '', string_to_convert).replace(' ', \"_\")\n",
    "    return filtered_string\n",
    "\n",
    "def find_twbx_file(inputfile):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     input: any input file\n",
    "#     output: returns the file name without any special char for a twxb file if one is found, else returns empty string\n",
    "#     \"\"\"\n",
    "\n",
    "    if inputfile[-5:] == '.twbx':\n",
    "        sp_packagedWorkbook = inputfile[:len(inputfile)-5]\n",
    "       \n",
    "        packagedWorkbook = removeSpecialCharFromStr(sp_packagedWorkbook)+'.twbx'\n",
    "        \n",
    "        old_file = join(input_path, sp_packagedWorkbook+'.twbx')\n",
    "        new_file = join(input_path, packagedWorkbook)\n",
    "        os.rename(old_file, new_file)\n",
    "\n",
    "    else:\n",
    "        packagedWorkbook = \"\" \n",
    "    \n",
    "    return packagedWorkbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in input_files: \n",
    "    packagedWorkbook = find_twbx_file(i)\n",
    "    print('Packaged workbook (no sp char): ' + packagedWorkbook)\n",
    "\n",
    "    #substring to be used when naming the exported data, NEEDS A PACKAGED WORKBOOK TO EXIST, OTHERWISE IT WILL GIVE AN EMPTY STRING\n",
    "    tableau_name_substring = packagedWorkbook.replace(\".twbx\",\"\")[:30]\n",
    "    print('\\nOutput docs name (word/pdf): ' + tableau_name_substring)\n",
    "    \n",
    "packagedTableauFile_relPath = input_path+\"/\"+packagedWorkbook\n",
    "packagedTableauFile_relPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "#get all fields in workbook\n",
    "TWBX_Workbook = Workbook(packagedTableauFile_relPath)\n",
    "\n",
    "collator = []\n",
    "calcID = []\n",
    "calcID2 = []\n",
    "calcNames = []\n",
    "\n",
    "c = 0\n",
    "    \n",
    "for datasource in TWBX_Workbook.datasources:\n",
    "    datasource_name = datasource.name\n",
    "    datasource_caption = datasource.caption if datasource.caption else datasource_name\n",
    "\n",
    "    for count, field in enumerate(datasource.fields.values()):\n",
    "        dict_temp = {\n",
    "            'counter': c,\n",
    "            'datasource_name': datasource_name,\n",
    "            'datasource_caption': datasource_caption,\n",
    "            'alias': field.alias,\n",
    "            'field_calculation': field.calculation,\n",
    "            'field_calculation_bk': field.calculation,\n",
    "            'field_caption': field.caption,\n",
    "            'field_datatype': field.datatype,\n",
    "            'field_def_agg': field.default_aggregation,\n",
    "            'field_desc': field.description,\n",
    "            'field_hidden': field.hidden,\n",
    "            'field_id': field.id,\n",
    "            'field_is_nominal': field.is_nominal,\n",
    "            'field_is_ordinal': field.is_ordinal,\n",
    "            'field_is_quantitative': field.is_quantitative,\n",
    "            'field_name': field.name,\n",
    "            'field_role': field.role,\n",
    "            'field_type': field.type,\n",
    "            'field_worksheets': field.worksheets,\n",
    "            'field_WHOLE': field\n",
    "        }\n",
    "\n",
    "        if field.calculation is not None:\n",
    "            calcID.append(field.id)\n",
    "            calcNames.append(field.name)\n",
    "\n",
    "            f2 = field.id.replace(']', '').replace('[', '')\n",
    "            calcID2.append(f2)\n",
    "\n",
    "        c += 1\n",
    "        collator.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_to_friendly_names2(formulaList,fieldToConvert, dictToUse):\n",
    "\n",
    "    for i in formulaList:\n",
    "        for tableauName, friendlyName in dictToUse.items():\n",
    "            try:\n",
    "                i[fieldToConvert] = (i[fieldToConvert]).replace(tableauName, friendlyName)\n",
    "            except:\n",
    "                a = 0\n",
    "       \n",
    "    return formulaList\n",
    "\n",
    "\n",
    "def category_field_type(row):\n",
    "    if row['datasource_name'] == 'Parameters':\n",
    "        val = 'Parameters'\n",
    "    elif row['field_calculation'] == None:\n",
    "        val = 'Default_Field'\n",
    "    else:\n",
    "        val = 'Calculated_Field'\n",
    "    return val\n",
    "\n",
    "def compare_fields(row):\n",
    "    if row['field_id'] == row['field_id2']:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calcDict = dict(zip(calcID, calcNames))\n",
    "calcDict2 = dict(zip(calcID2, calcNames)) #raw fields without any []\n",
    "\n",
    "collator = default_to_friendly_names2(collator,'field_calculation',calcDict2)\n",
    "\n",
    "df_API_all = pd.DataFrame(collator)\n",
    "df_API_all['field_type'] = df_API_all.apply(category_field_type, axis=1)\n",
    "\n",
    "preference_list=['Parameters', 'Calculated_Field', 'Default_Field']\n",
    "df_API_all[\"field_type\"] = pd.Categorical(df_API_all[\"field_type\"], categories=preference_list, ordered=True)\n",
    "\n",
    "#get rid of duplicates for parameters, so only parameters from the explicit Parameters datasource are kept (as they are also listed again under the name of any other datasources)\n",
    "df_API_all = df_API_all.sort_values([\"field_id\",\"field_type\"]).drop_duplicates([\"field_id\", 'field_calculation']) \n",
    "\n",
    "df_API_all['field_id2'] = df_API_all['field_id'].str.replace(r'[\\[\\]]', '', regex=True)\n",
    "\n",
    "df_API_all['comparison'] = df_API_all.apply(compare_fields, axis=1)\n",
    "df_API_all = df_API_all[df_API_all['comparison'] == 1]\n",
    "\n",
    "df_API_all = df_API_all.drop(['field_id2', 'comparison'], axis=1)\n",
    "df_API_all.sort_values(['datasource_name', 'field_type', 'counter', 'field_name'])\n",
    "\n",
    "df1 = df_API_all[[ 'field_name', 'field_datatype','field_type',  'field_calculation',   'field_id', 'datasource_caption']].copy()\n",
    "\n",
    "preference_list=[ 'Default_Field', 'Parameters', 'Calculated_Field']\n",
    "df1[\"field_type\"] = pd.Categorical(df1[\"field_type\"], categories=preference_list, ordered=True)\n",
    "df1 = df1.sort_values(['field_type'])\n",
    "\n",
    "df1.columns = ['Field_Name', 'DataType', 'Type', 'Calculation', 'Field_ID', 'Datasource']\n",
    "\n",
    "df1['Field_Name'] = df1['Field_Name'].str.replace(r'[\\[\\]]', '', regex=True)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an excel file from a df (so the excel rows/cols can be formatted), then turning the excel into a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify this part if you want to add more information/dfs to be saved as a separate sheet in excel\n",
    "\n",
    "dfs_to_use = [{'excelSheetTitle': 'All fields extracted from DOC API', 'df_to_use':df1, 'mainColWidth':'' , \n",
    "               'normalColWidth': [10,15,50,20, 25], 'sheetName': 'GeneralDetails', 'footer': 'Data_1 (DOC API)', 'papersize':9, 'color': '#fff0b3'}                \n",
    "             \n",
    "             ]\n",
    "\n",
    "#papersize: a3 = 8, a4 = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_excel_file_to_create, path_pdf_file_to_create = exg.create_new_file_paths(tableau_name_substring+'_CALCS_only')\n",
    "\n",
    "exg.create_excel_from_dfs(dfs_to_use, path_excel_file_to_create)\n",
    "\n",
    "exg.create_pdf_from_excel(path_excel_file_to_create, path_pdf_file_to_create, dfs_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of mermaid module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_char_checker(cell_value):\n",
    "    if cell_value[0] != '[':\n",
    "        cell_value = '__' + cell_value + '__'\n",
    "    else:\n",
    "        cell_value = cell_value.replace('[', '__')\n",
    "        cell_value = cell_value.replace(']', '__')\n",
    "\n",
    "    return cell_value\n",
    "\n",
    "\n",
    "#define abc list to use during mermaid creation\n",
    "\n",
    "abc=list(string.ascii_uppercase)\n",
    "collated_abc = []\n",
    "\n",
    "for i in abc:\n",
    "    for j in abc:\n",
    "        collated_abc.append(i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_fields = df1[df1['Type'] == 'Default_Field']['Field_ID'].copy().apply(remove_sp_char_leave_undescore_square_brackets)\n",
    "\n",
    "abc_touse = collated_abc[0:len(def_fields)]\n",
    "\n",
    "def_fields_final = pd.DataFrame(list(zip(def_fields.tolist(), abc_touse)))\n",
    "def_fields_final['aa'] = def_fields_final.apply(lambda row: first_char_checker(row[0]), axis=1)\n",
    "def_fields_final['default_field'] = def_fields_final.apply(lambda row: '_st_' + row['aa'] + '_en_', axis=1)\n",
    "\n",
    "mapping_dict_friendly_names = dict(zip(def_fields_final[0].tolist(), abc_touse))\n",
    "mapping_dict = dict(zip(def_fields_final['aa'].tolist(), abc_touse))\n",
    "\n",
    "def_fields_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "created_calc = df_API_all[df_API_all['field_type'] != 'Default_Field']\\\n",
    "                [['field_name', 'field_id', 'field_calculation', 'field_calculation_bk']].copy()\n",
    "\n",
    "nlsi = ['x___' + i for i in collated_abc]\n",
    "nlsi_to_use = nlsi[0:len(created_calc)]\n",
    "\n",
    "created_calc['field_name'] = created_calc['field_name'].apply(remove_sp_char_leave_undescore_square_brackets)\n",
    "created_calc['aa'] = created_calc.apply(lambda row: first_char_checker(row['field_id']), axis=1)\n",
    "created_calc['calc_field'] = created_calc.apply(lambda row: '_st_' + row['aa'] + '_en_', axis=1)\n",
    "created_calc['field_calculation_bk'] = created_calc['field_calculation_bk'].str.replace(r'[\\[\\]]', '__', regex=True)\n",
    "\n",
    "created_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_map_dict = dict(zip(created_calc['aa'].to_list(), nlsi_to_use))\n",
    "calc_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "created_calc['shorthand_abc'] = created_calc['aa'].map(calc_map_dict)\n",
    "created_calc.sort_values(by='shorthand_abc', inplace = True)\n",
    "created_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add suffixes to duplicate values\n",
    "def differentiate_duplicates(series):\n",
    "    counts = series.groupby(series).cumcount() \n",
    "    return series + counts.astype(str).replace('0', '')\n",
    "\n",
    "# differentiate field names that have duplicate values (eg. calc field Index appears twice in workbook, now it will be Index, Index1)\n",
    "created_calc['field_name'] = differentiate_duplicates(created_calc['field_name'])\n",
    "\n",
    "created_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_map_dict_friendly_names = dict(zip(created_calc['field_name'], created_calc['shorthand_abc'] ))\n",
    "calc_map_dict_friendly_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mermaid_paths(df, field_type):\n",
    "    \n",
    "    c = 0\n",
    "    t_collator = []\n",
    "\n",
    "    for i in df['aa']:\n",
    "\n",
    "        print('\\n______________________' + field_type.upper() + ' TO ANALYSE ________________________: ' + i + '\\n')\n",
    "\n",
    "        try:\n",
    "            tlist = created_calc[created_calc['field_calculation_bk'].str.contains(i, regex=False) == True]['aa'].to_list()\n",
    "        except:\n",
    "            tlist = []\n",
    "\n",
    "        if len(tlist) != 0:\n",
    "            print('LIST PRINTING:\\n\\n' + str(tlist))\n",
    "\n",
    "            for x in tlist:\n",
    "                newdict = {}\n",
    "\n",
    "                newdict['count'] = c\n",
    "                newdict['starting'] = i\n",
    "                newdict['ending'] = x\n",
    "\n",
    "                newdict['path_mermaid'] = i + \" --> \" + x\n",
    "\n",
    "                print('\\n' + str(c) + ' ******************NEW DICT PRINTING ********************** \\n\\n' + str(newdict))\n",
    "\n",
    "                t_collator.append(newdict)\n",
    "\n",
    "                c = c + 1\n",
    "    \n",
    "    return t_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_collator_def_fields = create_mermaid_paths(def_fields_final, 'default_field')\n",
    "t_collator_def_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_collator_calcs = create_mermaid_paths(created_calc, 'calculation')\n",
    "t_collator_calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#replace the full names of fields and calcs for their abbrv letters, to make the mermaid code leaner\n",
    "\n",
    "for default_field, mapping_letter in mapping_dict.items():\n",
    "    for i in t_collator_def_fields:\n",
    "        i['path_mermaid'] = i['path_mermaid'].replace(default_field, mapping_letter)\n",
    "\n",
    "for default_field, mapping_letter in calc_map_dict.items():\n",
    "    for i in t_collator_def_fields:\n",
    "        i['path_mermaid'] = i['path_mermaid'].replace(default_field, mapping_letter)\n",
    "\n",
    "t_collator_def_fields\n",
    "##############################\n",
    "\n",
    "##############################\n",
    "# replace the full names of fields and calcs for their abbrv letters, to make the mermaid code leaner\n",
    "\n",
    "for default_field, mapping_letter in mapping_dict.items():\n",
    "    for i in t_collator_calcs:\n",
    "        i['path_mermaid'] = i['path_mermaid'].replace(default_field, mapping_letter)\n",
    "\n",
    "for default_field, mapping_letter in calc_map_dict.items():\n",
    "    for i in t_collator_calcs:\n",
    "        i['path_mermaid'] = i['path_mermaid'].replace(default_field, mapping_letter)\n",
    "\n",
    "t_collator_calcs\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_a = ['']\n",
    "fields_list = ['']\n",
    "\n",
    "new_list_a.extend([i['path_mermaid'] for i in t_collator_calcs])\n",
    "new_list_a.extend([i['path_mermaid'] for i in t_collator_def_fields])\n",
    "\n",
    "################################\n",
    "#find the unique nodes within the a --> b mermaid paths in new_list_a (eg. a and b)\n",
    "c = []\n",
    "\n",
    "for i in new_list_a:\n",
    "    print(i)\n",
    "    c.append(i.split(' --> ')[0])\n",
    "\n",
    "    try:\n",
    "        c.append(i.split(' --> ')[1])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "c.pop(0)\n",
    "s = set(c)\n",
    "c = list(s)\n",
    "##############################\n",
    "\n",
    "for i, d in mapping_dict_friendly_names.items():\n",
    "    if d in c:\n",
    "        if i[0] != '[':\n",
    "            print(d + \"[\" + i + \"]\")\n",
    "            fields_list.append(d + \"[\" + i + \"]:::foo\")\n",
    "        else:\n",
    "            print(d + i)\n",
    "            fields_list.append(d + i + ':::foo')\n",
    "\n",
    "for i, d in calc_map_dict_friendly_names.items():\n",
    "    if d in c:\n",
    "        print(d + \"[\" + i + \"]\")\n",
    "        fields_list.append(d + \"[\" + i + \"]\")\n",
    "        \n",
    "superfinallist =  fields_list + new_list_a\n",
    "superfinallist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mermaid_diagram_code = \\\n",
    "\"\"\"\n",
    "flowchart LR\n",
    "    classDef foo fill:#f9f,stroke:#333,stroke-width:1px{}\n",
    "\"\"\".format(\"\\n\\t\".join(superfinallist))\n",
    "\n",
    "print(mermaid_diagram_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create html which will display the mermaid diagram\n",
    "\n",
    "\n",
    "html_base = \"\"\"\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>\"\"\" + tableau_name_substring + \" Calculation Lineage\" + \"\"\"</title>\n",
    "    <!-- Include Mermaid.js library -->\n",
    "    <script type=\"module\">\n",
    "      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n",
    "      mermaid.initialize({ startOnLoad: true });\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>\"\"\" +  tableau_name_substring + \" Calculation Lineage\" + \"\"\"</h1>\n",
    "    <!-- Mermaid diagram definition -->\n",
    "    <div class=\"mermaid\">\"\"\" + mermaid_diagram_code + \"\"\"</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "print('\\n ______________________________ START_OF_HTML ______________________________')\n",
    "print(html_base)\n",
    "print('\\n ______________________________ END_OF_HTML ______________________________')\n",
    "\n",
    "\n",
    "### Output html string to a local file, then open it on the web browser (this bit was done with help of chatgpt)\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'outputs\\mermaid_diagram_{}.html'.format(tableau_name_substring)\n",
    "\n",
    "# Write the string to an HTML file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(html_base)\n",
    "\n",
    "print(\"HTML content successfully written to {}\".format(file_path))\n",
    "\n",
    "# Open the HTML file in the default web browser\n",
    "webbrowser.open('file://' + os.path.realpath(file_path))\n",
    "\n",
    "### end of chatgpt code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
