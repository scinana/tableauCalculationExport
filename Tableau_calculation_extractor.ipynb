{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 2.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, sys, pathlib, zipfile\n",
    "import win32com.client\n",
    "import xml.etree.ElementTree as ET\n",
    "import tableaudocumentapi\n",
    "\n",
    "from tableaudocumentapi import Workbook\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input folder - Find if there is a twbx or twb file in the folder\n",
    "- if there is a twbx, unzip it to create a twb, then work with this\n",
    "- if there's only a twb, work with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_path = \"inputs\"\n",
    "output_path = \"outputs\"\n",
    "\n",
    "mypath = \"./{}\".format(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#only gets files and not directories within the inputs folder -https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "f = [f for f in os.listdir(mypath) if isfile(join(mypath, f)) and f[-5:] == '.twbx'] \n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharFromStr(spstring):\n",
    "  \n",
    "    return ''.join(e for e in spstring if e.isalnum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in f: \n",
    "   \n",
    "    if i[-5:] == '.twbx':\n",
    "        sp_packagedWorkbook = i[:len(i)-5]\n",
    "        print(sp_packagedWorkbook)\n",
    "        packagedWorkbook = removeSpecialCharFromStr(sp_packagedWorkbook)+'.twbx'\n",
    "        print(packagedWorkbook)\n",
    "        \n",
    "        old_file = join(input_path, sp_packagedWorkbook+'.twbx')\n",
    "        new_file = join(input_path, packagedWorkbook)\n",
    "        os.rename(old_file, new_file)\n",
    "        \n",
    "        with zipfile.ZipFile(input_path+\"/\"+packagedWorkbook, 'r') as zip_ref:\n",
    "            zip_ref.extractall(input_path+\"/\")\n",
    "    else:\n",
    "        packagedWorkbook = \"\"\n",
    "        \n",
    "for i in [f for f in os.listdir(mypath) if isfile(join(mypath, f))] :\n",
    "    \n",
    "    if i[-4:] == '.twb':\n",
    "        sp_unpackagedWorkbook = i[:len(i)-4]\n",
    "        unpackedWorkbook = removeSpecialCharFromStr(sp_unpackagedWorkbook)+'.twb' \n",
    "        \n",
    "        old_file = join(input_path, sp_unpackagedWorkbook+'.twb')\n",
    "        new_file = join(input_path, unpackedWorkbook)\n",
    "        os.rename(old_file, new_file)\n",
    "\n",
    "print('\\n')\n",
    "print('packaged workbook: ' + packagedWorkbook)\n",
    "print('unpackaged workbook: ' + unpackedWorkbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableauFile = input_path+\"/\"+unpackedWorkbook\n",
    "tableauFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packagedTableauFile = input_path+\"/\"+packagedWorkbook\n",
    "packagedTableauFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substring to be used when naming the exported data\n",
    "\n",
    "tableau_name_substring = packagedWorkbook.replace(\".twbx\",\"\")[:30]\n",
    "tableau_name_substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse xml to get all calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(tableauFile)\n",
    "root = tree.getroot()\n",
    "\n",
    "collator1 = []\n",
    "calcNames = []\n",
    "calcCaptions = []\n",
    "\n",
    "for_findall = [\"./datasources/datasource/column\", \"./worksheets/worksheet/table/view/datasource-dependencies/column\"]\n",
    "\n",
    "for pathy in for_findall:\n",
    "    for elem in root.findall(pathy):\n",
    "\n",
    "        dict_temp = {}\n",
    "\n",
    "        if (elem.findall('calculation')) != []:    #only get nodes where there is a calculation\n",
    "            try:\n",
    "                dict_temp['caption'] = elem.attrib['caption']\n",
    "                calcCaptions.append(elem.attrib['caption'])\n",
    "            except:\n",
    "                dict_temp['caption'] = elem.attrib['name'] #DEPRECATED #'MISSING'\n",
    "                calcCaptions.append(elem.attrib['name'])  #DEPRECATED append('MISSING')\n",
    "\n",
    "            dict_temp['datatype'] = elem.attrib['datatype']\n",
    "            dict_temp['name'] = elem.attrib['name']\n",
    "\n",
    "            f2 = (elem.attrib['name']).replace(']','')\n",
    "            f2 = f2.replace('[', '')\n",
    "            calcNames.append(f2)\n",
    "\n",
    "            try: #this part evaluates for a parameter\n",
    "                paramExists = elem.attrib['param-domain-type']\n",
    "                dict_temp['isParameter'] = 'yes'\n",
    "                dict_temp['formula'] = 'NA'\n",
    "\n",
    "            except: #this part is for calculations only (not parameters)\n",
    "                dict_temp['isParameter'] = 'no'\n",
    "\n",
    "                try:\n",
    "                    for calc in elem.findall('calculation'):\n",
    "                        dict_temp['formula'] = calc.attrib['formula']\n",
    "                except:\n",
    "\n",
    "                    dict_temp['formula'] = 'NA'\n",
    "\n",
    "            collator1.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcDict = dict(zip(calcNames, calcCaptions))\n",
    "calcDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_to_friendly_names(formulaList):\n",
    "\n",
    "    for i in formulaList:\n",
    "        for tableauName, friendlyName in calcDict.items():\n",
    "            i['formula'] = (i['formula']).replace(tableauName, friendlyName)\n",
    "       \n",
    "    return formulaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collator1 = default_to_friendly_names(collator1)\n",
    "collator1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(collator1)\n",
    "df = df[['caption', 'datatype', 'formula', 'isParameter', 'name']]\n",
    "df.columns = ['CalculationName', 'DataType', 'Formula', 'isParameter', 'RawName']\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df = df.sort_values(by=['isParameter','CalculationName'])\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all filters for all worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(tableauFile)\n",
    "root = tree.getroot()\n",
    "\n",
    "filters_in_sheet = []\n",
    "context = []\n",
    "collatelist = []\n",
    "\n",
    "for worskheet in root.findall(\"./worksheets/worksheet\"):\n",
    "    \n",
    "    tempdict = {}\n",
    "    c = 0\n",
    "    \n",
    "    for filt in worskheet.findall('table/view/filter'):\n",
    "\n",
    "        calcfromfilter = filt.attrib['column']        \n",
    "        pat = '(?<=\\:)(.*?)(?=\\:)' \n",
    "        string_cleaned = calcfromfilter.split('].[')[1].replace(']','')\n",
    "        \n",
    "        tempdict['field'] = calcfromfilter\n",
    "        tempdict['formula'] = calcfromfilter\n",
    "        tempdict['counter'] = c\n",
    "        tempdict['sheetname'] = worskheet.attrib['name']\n",
    "        \n",
    "        try:\n",
    "            st1 = re.findall(pat,string_cleaned)[0]\n",
    "            tempdict['field'] = st1\n",
    "            tempdict['formula'] = st1\n",
    "            collatelist.append(tempdict)\n",
    "            \n",
    "        except:\n",
    "            st2 = string_cleaned.replace(':','')\n",
    "            tempdict['field'] = st2\n",
    "            tempdict['formula'] = st2\n",
    "            collatelist.append(tempdict)\n",
    "\n",
    "        try:\n",
    "            tempdict['context'] = filt.attrib['context']\n",
    "        except:\n",
    "            tempdict['context'] = 'False'\n",
    "           \n",
    "        c = c + 1\n",
    "        tempdict = {}\n",
    "    \n",
    "collatelist[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collatelist = default_to_friendly_names(collatelist)\n",
    "collatelist[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    df1 = pd.DataFrame(collatelist)\n",
    "\n",
    "    df1 = df1[['sheetname', 'formula', 'context', 'field']]\n",
    "    df1.columns = ['Sheet Name', 'FilterField', 'Context filter', 'FilterField_RawName']\n",
    "\n",
    "    print(df1.head(2))\n",
    "except:\n",
    "    print('error with df1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting rows and cols for each sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collecteddata = []\n",
    "\n",
    "for worksheet in root.findall(\"./worksheets/worksheet\"):\n",
    "\n",
    "    argumentstopass = ['rows', 'cols']\n",
    "    \n",
    "    for i in argumentstopass:   \n",
    "    \n",
    "        internaldict = {}\n",
    "\n",
    "        internaldict['sheetname'] = worksheet.attrib['name']\n",
    "        internaldict['type'] = i\n",
    "        \n",
    "        formulahere = worksheet.findall('table/'+i)[0].text\n",
    "        internaldict['formula'] = formulahere\n",
    "        \n",
    "        collecteddata.append(internaldict)\n",
    "    \n",
    "collecteddata[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in collecteddata:\n",
    "\n",
    "    try:\n",
    "        pattern = '\\:.*?\\:'\n",
    "        pat = '(?<=\\:)(.*?)(?=\\:)'\n",
    "\n",
    "        calculationsWithColon = re.findall(pattern,i['formula']) \n",
    "        calcsWithoutColon = []\n",
    "\n",
    "        for n in calculationsWithColon:\n",
    "            oneCalcWithoutColon = re.findall(pat,n)[0]\n",
    "\n",
    "            calcsWithoutColon.append(oneCalcWithoutColon)\n",
    "            \n",
    "        i['extracted formulas'] = calcsWithoutColon\n",
    "        \n",
    "    except:\n",
    "        i['extracted formulas'] = []\n",
    "             \n",
    "    newcalcs = []\n",
    "    formulas_to_process = i['extracted formulas']\n",
    "    \n",
    "    for n in formulas_to_process:\n",
    "           \n",
    "        for tableauName, friendlyName in calcDict.items():\n",
    "            \n",
    "            n = n.replace(tableauName, friendlyName)\n",
    "            \n",
    "        newcalcs.append(n)\n",
    "    \n",
    "    #version 2.35 added this part to check for longitude or latitute in the formula\n",
    "    #separate to other try/except as long/lat appear in a different string structure so cannot analyse with above regex\n",
    "    try:\n",
    "        if \"Longitude (generated)\" in i['formula']:\n",
    "            newcalcs.append(\"Longitude (generated)\")\n",
    "        elif \"Latitude (generated)\" in i['formula']:\n",
    "            newcalcs.append(\"Latitude (generated)\")\n",
    "    except:\n",
    "        dummy = 0\n",
    "    \n",
    "    i['processed formulas'] = newcalcs\n",
    "\n",
    "collecteddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(collecteddata)\n",
    "df2 = df2[['extracted formulas', 'formula', 'processed formulas', 'sheetname', 'type']]\n",
    "df2 = df2.drop(columns=['formula', 'extracted formulas'])\n",
    "df2 = df2.pivot(index='sheetname', columns='type', values='processed formulas')\n",
    "df2 = df2.reset_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All default fields - DOC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "packagedTableauFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get all fields in workbook\n",
    "sourceTWBX = Workbook(packagedTableauFile)\n",
    "\n",
    "collator = []\n",
    "calcID = []\n",
    "calcID2 = []\n",
    "calcNames = []\n",
    "\n",
    "c = 0\n",
    "\n",
    "worksheets = sourceTWBX.worksheets\n",
    "\n",
    "#for worksheet in worksheets: #see if this has to be marked out or not\n",
    "    \n",
    "for datasource in sourceTWBX.datasources:\n",
    "\n",
    "    for count, field in enumerate(datasource.fields.values()):\n",
    "\n",
    "                #if worksheet in field.worksheets: #removed this part so all fields are listed,as otherwise some fields were missed out\n",
    "\n",
    "            dict_temp = {}\n",
    "            dict_temp['counter'] = c\n",
    "            dict_temp['worksheet'] = worksheet\n",
    "            dict_temp['datasource_name'] = datasource.name\n",
    "            dict_temp['field_WHOLE'] = field\n",
    "            dict_temp['field_name'] = field.name\n",
    "            dict_temp['field_caption'] = field.caption\n",
    "            dict_temp['field_calculation'] = field.calculation\n",
    "            dict_temp['field_id'] = field.id\n",
    "            dict_temp['field_datatype'] = field.datatype\n",
    "\n",
    "\n",
    "            if not(isinstance(field.calculation, type(None))):\n",
    "                calcID.append(field.id)\n",
    "                calcNames.append(field.name)\n",
    "\n",
    "                f2 = (field.id).replace(']','')\n",
    "                f2 = f2.replace('[', '')\n",
    "                calcID2.append(f2)\n",
    "\n",
    "            c = c + 1\n",
    "\n",
    "            collator.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcDict = dict(zip(calcID, calcNames))\n",
    "calcDict2 = dict(zip(calcID2, calcNames)) #raw fields without any []\n",
    "\n",
    "def default_to_friendly_names2(formulaList,fieldToConvert, dictToUse):\n",
    "\n",
    "    for i in formulaList:\n",
    "        for tableauName, friendlyName in dictToUse.items():\n",
    "            try:\n",
    "                i[fieldToConvert] = (i[fieldToConvert]).replace(tableauName, friendlyName)\n",
    "            except:\n",
    "                a = 0\n",
    "       \n",
    "    return formulaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['field_calculation'] == None:\n",
    "        val = 'Datasource field'\n",
    "    else:\n",
    "        val = 'Calculated field'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_to_friendly_names2(collator,'field_calculation',calcDict)\n",
    "\n",
    "df_API_all = pd.DataFrame(collator)\n",
    "df_API_all['field_type'] = df_API_all.apply(f, axis=1)\n",
    "\n",
    "df_API_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_defaultFields = df_API_all[df_API_all['field_type'] == 'Datasource field'][['field_id', 'field_caption','field_datatype', 'datasource_name']].drop_duplicates().copy()\n",
    "\n",
    "df_defaultFields['prefOrder'] = np.where(df_defaultFields['field_caption'].isnull(), 0, 1)\n",
    "df_defaultFields['field_id2'] = df_defaultFields['field_id'].str.replace('[','')\n",
    "df_defaultFields['field_id2'] = df_defaultFields['field_id2'].str.replace(']','')\n",
    "\n",
    "df_defaultFields = df_defaultFields.sort_values(by = ['field_id2'])\n",
    "#https://stackoverflow.com/questions/63271050/use-drop-duplicates-in-pandas-df-but-choose-keep-column-based-on-a-preference-li\n",
    "preference_list=[1,0]\n",
    "\n",
    "df_defaultFields[\"prefOrder\"] = pd.Categorical(df_defaultFields[\"prefOrder\"], categories=preference_list, ordered=True)\n",
    "\n",
    "df_defaultFields = df_defaultFields.sort_values([\"field_id2\",\"prefOrder\"]).drop_duplicates(\"field_id2\")\n",
    "df_defaultFields = df_defaultFields.drop('prefOrder', axis=1)\n",
    "df_defaultFields = df_defaultFields.drop('field_id2', axis=1)\n",
    "df_defaultFields.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colsToUse = ['field_id', 'field_name', 'field_calculation', 'field_caption','field_datatype', 'datasource_name' ]\n",
    "dfAPIParameters = df_API_all[colsToUse][df_API_all['datasource_name']=='Parameters'].drop_duplicates().copy()\n",
    "\n",
    "dfAPIParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dfAPIParameters[['field_id','field_calculation']], left_on='RawName', right_on = 'field_id', how='left')\n",
    "\n",
    "df[\"Formula\"] = np.where(df[\"Formula\"] == \"NA\", df['field_calculation'], df[\"Formula\"])\n",
    "df = df.drop(columns=['field_id', 'field_calculation'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet - all field dependencies, not just the explicitly used fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_api_insheet\n",
    "sourceTWBX = Workbook(packagedTableauFile)\n",
    "\n",
    "collator_sheet_dependencies = []\n",
    "\n",
    "c = 0\n",
    "\n",
    "worksheets = sourceTWBX.worksheets\n",
    "\n",
    "for worksheet in worksheets:\n",
    "    \n",
    "    for datasource in sourceTWBX.datasources:\n",
    "       \n",
    "        for count, field in enumerate(datasource.fields.values()):\n",
    "            \n",
    "            if worksheet in field.worksheets: #to see if only fields that appear in sheets are listed, else last df is too large\n",
    "                \n",
    "                dict_temp = {}\n",
    "                dict_temp['counter'] = c\n",
    "                dict_temp['worksheet'] = worksheet\n",
    "                dict_temp['datasource_name'] = datasource.name\n",
    "                dict_temp['field_WHOLE'] = field\n",
    "                dict_temp['field_name'] = field.name\n",
    "                dict_temp['field_caption'] = field.caption\n",
    "                dict_temp['field_calculation'] = field.calculation\n",
    "                dict_temp['field_id'] = field.id\n",
    "                dict_temp['field_datatype'] = field.datatype\n",
    "                \n",
    "                c = c + 1\n",
    "                \n",
    "                collator_sheet_dependencies.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#default_to_friendly_names2(collator_sheet_dependencies, 'field_calculation',calcDict)\n",
    "\n",
    "df_api_insheet = pd.DataFrame(collator_sheet_dependencies)\n",
    "df_api_insheet['field_type'] = df_api_insheet.apply(f, axis=1)\n",
    "df_api_insheet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sheetDependencies = df_api_insheet.copy()\n",
    "preference_list=[1,0]\n",
    "\n",
    "df_sheetDependencies['prefOrder'] = np.where(df_sheetDependencies['field_caption'].isnull(), 0, 1)\n",
    "\n",
    "df_sheetDependencies['field_id2'] = df_sheetDependencies['field_id'].str.replace('[','')\n",
    "df_sheetDependencies['field_id2'] = df_sheetDependencies['field_id2'].str.replace(']','')\n",
    "\n",
    "df_sheetDependencies[\"prefOrder\"] = pd.Categorical(df_sheetDependencies[\"prefOrder\"], categories=preference_list, ordered=True)\n",
    "df_sheetDependencies = df_sheetDependencies.sort_values([\"field_id2\",\\\n",
    "                                                         \"prefOrder\"]).drop_duplicates(subset=[\"field_id2\", \"worksheet\"])\n",
    "\n",
    "df_sheetDependencies = df_sheetDependencies.drop(\\\n",
    "                                columns=['prefOrder', 'field_id2', 'counter', 'field_caption', 'field_WHOLE', \\\n",
    "                                         'field_calculation', 'field_id'])\n",
    "\n",
    "df_sheetDependencies = df_sheetDependencies[['worksheet', 'field_name', 'field_datatype', \\\n",
    "                                             'field_type', 'datasource_name']].sort_values(by = ['worksheet', 'field_type', 'field_name'])\n",
    "df_sheetDependencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General workbook description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceTWBX = Workbook(packagedTableauFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_list = []\n",
    "\n",
    "for dash in sourceTWBX.dashboards:\n",
    "    dicti = {}\n",
    "    \n",
    "    dicti['type'] = 'dashboard'\n",
    "  #  print(format(dash))\n",
    "    dicti['name'] = format(dash)\n",
    "   \n",
    "    collate_list.append(dicti)\n",
    "    \n",
    "for data in sourceTWBX.datasources:\n",
    "    dicti = {}\n",
    "    \n",
    "    dicti['type'] = 'datasource'\n",
    "    dicti['name'] = format(data.name)\n",
    "   # print(format(data.name))\n",
    "   \n",
    "    collate_list.append(dicti)\n",
    "    \n",
    "for data in sourceTWBX.worksheets:\n",
    "    dicti = {}\n",
    "    \n",
    "    dicti['type'] = 'sheet'\n",
    "    dicti['name'] = format(data)\n",
    "   # print(format(data))\n",
    "    \n",
    "    collate_list.append(dicti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_workbookdec = pd.DataFrame(collate_list)\n",
    "df_workbookdec = df_workbookdec[['type', 'name']]\n",
    "df_workbookdec.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_workbookdec_counts = df_workbookdec.groupby(['type']).count().reset_index()\n",
    "df_workbookdec_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count parameters and calc fields, based on xml scraping\n",
    "parameterCount = len(df[df['isParameter'] == 'yes'])\n",
    "calcFieldCount = len(df[df['isParameter'] != 'yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row1 = {'type':'parameter', 'name':parameterCount}\n",
    "new_row2 = {'type':'calculated field', 'name':calcFieldCount}\n",
    "\n",
    "toappend = [new_row1, new_row2]\n",
    "\n",
    "for i in toappend:\n",
    "#append row to the dataframe\n",
    "    df_workbookdec_counts = df_workbookdec_counts.append(i, ignore_index=True)\n",
    "\n",
    "df_workbookdec_counts.columns = ['type', 'count']\n",
    "df_workbookdec_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an excel file from a df (so the excel rows/cols can be formatted), then turning the excel into a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "path_string = pathlib.Path(cwd).resolve().__str__() + \"\\{}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the file names and output locations for the excel and pdfs to be produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_use = tableau_name_substring    \n",
    "\n",
    "newFileName = 'outputs\\{}'.format(name_to_use)\n",
    "excelName = newFileName + \".xlsx\"\n",
    "pdfName = newFileName + \".pdf\"\n",
    "print(pdfName)\n",
    "\n",
    "excel_path = path_string.format(excelName)\n",
    "path_to_pdf = path_string.format(pdfName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to format the excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors to be used in each sheet\n",
    "c1 = '#f4dfa4'\n",
    "c2 = '#ffc8b3'\n",
    "c3 = '#fff0b3'\n",
    "c4 = '#d5dfb9'\n",
    "c5 = '#d1c5d3'\n",
    "c6 = '#bfd9d7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainCol(colNumber, color):\n",
    "    format_mainCol = workbook.add_format({'text_wrap': True, 'bold': True})\n",
    "    format_mainCol.set_align('vcenter')\n",
    "    format_mainCol.set_bg_color(color)\n",
    "    format_mainCol.set_border(1)\n",
    "    worksheet.set_column(colNumber,colNumber,20,format_mainCol)\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalCol(colNumber, colWidth):\n",
    "    format2 = workbook.add_format({'text_wrap': True})\n",
    "    format2.set_align('vcenter')\n",
    "    format2.set_border(1)\n",
    "    worksheet.set_column(colNumber,colNumber,colWidth,format2)\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify this part if you want to add more information/dfs to be saved as a separate sheet in excel\n",
    "\n",
    "dfs_to_use = [{'excelSheetTitle': 'Dashboard, datasource and sheet details', 'df_to_use':df_workbookdec, 'mainColWidth':'' , \n",
    "               'normalColWidth': [30], 'sheetName': 'GeneralDetails', 'footer': 'Data_1 (DOC API)', 'papersize':9, 'color': c1} , \n",
    "              \n",
    "              {'excelSheetTitle': 'Overall counts of dashboards, datasources and sheets', 'df_to_use':df_workbookdec_counts, 'mainColWidth':'' , \n",
    "               'normalColWidth': [10], 'sheetName': 'GeneralCounts', 'footer': 'Data_2 (DOC API + XML)', 'papersize':9, 'color': c1},\n",
    "              \n",
    "              {'excelSheetTitle': 'Default fields from all datasources', 'df_to_use':df_defaultFields, 'mainColWidth':'' , \n",
    "               'normalColWidth': [20,20,40], 'sheetName': 'DefaultFields', 'footer': 'Data_3 (XML extraction)', 'papersize':9, 'color': c2},\n",
    "              \n",
    "              {'excelSheetTitle': 'Calculated fields and parameters', 'df_to_use':df, 'mainColWidth':'' , \n",
    "               'normalColWidth': [10,50,10,20], 'sheetName': 'CalculatedFields', 'footer': 'Data_4 (XML extraction + DOC API for Param value)', \n",
    "               'papersize':9, 'color': c3},\n",
    "              \n",
    "              {'excelSheetTitle': 'Filters used in each sheet', 'df_to_use':df1, 'mainColWidth':'' , \n",
    "               'normalColWidth': [20,20,40], 'sheetName': 'Filters', 'footer': 'Data_5 (XML extraction)', 'papersize':9, 'color': c4},\n",
    "              \n",
    "              {'excelSheetTitle': 'Metrics used in Columns and Rows, for each sheet', 'df_to_use':df2, 'mainColWidth':'' , \n",
    "               'normalColWidth': [30,40], 'sheetName': 'RowsAndCols', 'footer': 'Data_6 (XML extraction)', 'papersize':9, 'color': c5},\n",
    "              \n",
    "              {'excelSheetTitle': 'Sheet dependencies on default fields, calculated fields and parameters', 'df_to_use':df_sheetDependencies, 'mainColWidth':'' , \n",
    "               'normalColWidth': [30,15,25,30], 'sheetName': 'SheetDependencies', 'footer': 'Data_7 (DOC API)', 'papersize':8, 'color': c6}\n",
    "             ]\n",
    "\n",
    "#papersize: a3 = 8, a4 = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(excelName, engine = 'xlsxwriter')\n",
    "\n",
    "#code to create each sheet in excel, with the specified df and formatting each sheet as per requirements\n",
    "#also adds a header and footer to each sheet\n",
    "#all the info to be replaced below (ie. for each df) comes form the dfs_to_use list of dictionaries\n",
    "\n",
    "for x in dfs_to_use:\n",
    "    excelSheetTitle = x['excelSheetTitle']\n",
    "    df_to_use = x['df_to_use']\n",
    "    normalColWidth = x['normalColWidth']\n",
    "    sheetName = x['sheetName']\n",
    "    papersize = x['papersize']\n",
    "    footer = x['footer']\n",
    "    color = x['color']\n",
    "\n",
    "    df_to_use.to_excel(writer, sheet_name = sheetName, index=False)\n",
    "    \n",
    "    workbook=writer.book\n",
    "    worksheet = writer.sheets[sheetName]\n",
    "\n",
    "    worksheet = mainCol(0, color)\n",
    "    \n",
    "    ws = 1\n",
    "    for i in normalColWidth:\n",
    "        worksheet = normalCol(ws,i)\n",
    "        ws = ws + 1\n",
    "\n",
    "    worksheet.set_paper(papersize) # a4\n",
    "    worksheet.fit_to_pages(1,0)    # fit to 1 page wide, n long\n",
    "    worksheet.repeat_rows(0)       # repeat the first row\n",
    "    \n",
    "    header_x = '&C&\"Arial,Bold\"&10{}'.format(excelSheetTitle)\n",
    "    footer_x = '&L{}&CPage &P of &N'.format(footer)\n",
    "\n",
    "    worksheet.set_header(header_x)\n",
    "    worksheet.set_footer(footer_x)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of pdf from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates an index to list each excel sheet, based on the number of sheets that were created before\n",
    "\n",
    "for_ws_index_list = []\n",
    "for i in range(len(dfs_to_use)):\n",
    "    for_ws_index_list.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = win32com.client.Dispatch(\"Excel.Application\")\n",
    "excel.Visible = False\n",
    "\n",
    "wb = excel.Workbooks.Open(excel_path)\n",
    "\n",
    "#print all the excel sheets into a single pdf\n",
    "ws_index_list = for_ws_index_list\n",
    "wb.Worksheets(ws_index_list).Select()\n",
    "wb.ActiveSheet.ExportAsFixedFormat(0, path_to_pdf)\n",
    "wb.Close()\n",
    "excel.Quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
